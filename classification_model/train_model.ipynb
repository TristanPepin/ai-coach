{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from skimage import transform\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tabular_dataset(srcpath,name):\n",
    "\n",
    "    exercices = os.listdir(srcpath)\n",
    "\n",
    "\n",
    "    if not os.path.exists(srcpath + '/' + name + '.csv') :\n",
    "        data_train = pd.DataFrame(columns = ['NOISE_X', \n",
    "                                             'NOISE_Y',\n",
    "                                             'LEFT_SHOULDER_X',\n",
    "                                             'LEFT_SHOULDER_Y',\n",
    "                                             'RIGHT_SHOULDER_X',\n",
    "                                             'RIGHT_SHOULDER_Y',\n",
    "                                             'LEFT_ELBOW_X',\n",
    "                                             'LEFT_ELBOW_Y',\n",
    "                                             'RIGHT_ELBOW_X',\n",
    "                                             'RIGHT_ELBOW_Y',\n",
    "                                             'LEFT_WRIST_X',\n",
    "                                             'LEFT_WRIST_Y',\n",
    "                                             'RIGHT_WRIST_X',\n",
    "                                             'RIGHT_WRIST_Y',\n",
    "                                             'LEFT_PINKY_X',\n",
    "                                             'LEFT_PINKY_Y',\n",
    "                                             'RIGHT_PINKY_X',\n",
    "                                             'RIGHT_PINKY_Y',\n",
    "                                             'LEFT_INDEX_X',\n",
    "                                             'LEFT_INDEX_Y',\n",
    "                                             'RIGHT_INDEX_X',\n",
    "                                             'RIGHT_INDEX_Y',\n",
    "                                             'LEFT_THUMB_X',\n",
    "                                             'LEFT_THUMB_Y',\n",
    "                                             'RIGHT_THUMB_X',\n",
    "                                             'RIGHT_THUMB_Y',\n",
    "                                             'LEFT_HIP_X',\n",
    "                                             'LEFT_HIP_Y',\n",
    "                                             'RIGHT_HIP_X',\n",
    "                                             'RIGHT_HIP_Y',\n",
    "                                             'LEFT_KNEE_X',\n",
    "                                             'LEFT_KNEE_Y',\n",
    "                                             'RIGHT_KNEE_X',\n",
    "                                             'RIGHT_KNEE_Y',\n",
    "                                             'LEFT_ANKLE_X',\n",
    "                                             'LEFT_ANKLE_Y',\n",
    "                                             'RIGHT_ANKLE_X',\n",
    "                                             'RIGHT_ANKLE_Y',\n",
    "                                             'LEFT_HEEL_X', \n",
    "                                             'LEFT_HEEL_Y',\n",
    "                                             'RIGHT_HEEL_X', \n",
    "                                             'RIGHT_HEEL_Y',\n",
    "                                             'LEFT_FOOT_INDEX_X', \n",
    "                                             'LEFT_FOOT_INDEX_Y',\n",
    "                                             'RIGHT_FOOT_INDEX_X', \n",
    "                                             'RIGHT_FOOT_INDEX_Y',\n",
    "                                             'PATH',\n",
    "                                             'EXERCICE'])\n",
    "\n",
    "    else : \n",
    "        data_train = pd.read_csv(srcpath + '/' + name + '.csv')\n",
    "\n",
    "    \n",
    "    for ex in exercices : \n",
    "        if 'csv' not in ex :\n",
    "            images = os.listdir(srcpath + '/' + ex)\n",
    "            print('Processing exercice ' + ex)\n",
    "            if len(images):\n",
    "                with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "\n",
    "                    for im in tqdm(images) :\n",
    "                        path = srcpath + '/' + ex + '/' + im\n",
    "\n",
    "                        try :\n",
    "                        \n",
    "                            if path not in data_train.PATH.unique() :\n",
    "\n",
    "                                image = cv2.imread(path)\n",
    "                                image.flags.writeable = False\n",
    "                                flip_image = tf.image.flip_left_right(image).numpy()\n",
    "                                to_process = {path : image,\n",
    "                                              path + '_fliped' : flip_image}\n",
    "\n",
    "\n",
    "                                for key in to_process.keys():\n",
    "\n",
    "                                    # Make detection\n",
    "                                    results = pose.process(to_process[key])\n",
    "                                    landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "\n",
    "                                    new_entry = {'NOISE_X' : landmarks[mp_pose.PoseLandmark.NOSE.value].x, \n",
    "                                                'NOISE_Y' : landmarks[mp_pose.PoseLandmark.NOSE.value].y,\n",
    "                                                'LEFT_SHOULDER_X' : landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                                                'LEFT_SHOULDER_Y' : landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y,\n",
    "                                                'RIGHT_SHOULDER_X' : landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                                                'RIGHT_SHOULDER_Y' : landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y,\n",
    "                                                'LEFT_ELBOW_X' : landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "                                                'LEFT_ELBOW_Y' : landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y,\n",
    "                                                'RIGHT_ELBOW_X' : landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                                                'RIGHT_ELBOW_Y': landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y,\n",
    "                                                'LEFT_WRIST_X' : landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                                                'LEFT_WRIST_Y' : landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y,\n",
    "                                                'RIGHT_WRIST_X' : landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                                                'RIGHT_WRIST_Y' : landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y,\n",
    "                                                'LEFT_PINKY_X' : landmarks[mp_pose.PoseLandmark.LEFT_PINKY.value].x,\n",
    "                                                'LEFT_PINKY_Y' : landmarks[mp_pose.PoseLandmark.LEFT_PINKY.value].y,\n",
    "                                                'RIGHT_PINKY_X' : landmarks[mp_pose.PoseLandmark.RIGHT_PINKY.value].x,\n",
    "                                                'RIGHT_PINKY_Y' : landmarks[mp_pose.PoseLandmark.RIGHT_PINKY.value].y,\n",
    "                                                'LEFT_INDEX_X' : landmarks[mp_pose.PoseLandmark.LEFT_INDEX.value].x,\n",
    "                                                'LEFT_INDEX_Y': landmarks[mp_pose.PoseLandmark.LEFT_INDEX.value].y,\n",
    "                                                'RIGHT_INDEX_X' : landmarks[mp_pose.PoseLandmark.RIGHT_INDEX.value].x,\n",
    "                                                'RIGHT_INDEX_Y' : landmarks[mp_pose.PoseLandmark.RIGHT_INDEX.value].y,\n",
    "                                                'LEFT_THUMB_X' : landmarks[mp_pose.PoseLandmark.LEFT_THUMB.value].x,\n",
    "                                                'LEFT_THUMB_Y' : landmarks[mp_pose.PoseLandmark.LEFT_THUMB.value].y,\n",
    "                                                'RIGHT_THUMB_X' : landmarks[mp_pose.PoseLandmark.RIGHT_THUMB.value].x,\n",
    "                                                'RIGHT_THUMB_Y' : landmarks[mp_pose.PoseLandmark.RIGHT_THUMB.value].y,\n",
    "                                                'LEFT_HIP_X' : landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                                                'LEFT_HIP_Y' : landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y,\n",
    "                                                'RIGHT_HIP_X' : landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                                                'RIGHT_HIP_Y' : landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y,\n",
    "                                                'LEFT_KNEE_X' : landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",
    "                                                'LEFT_KNEE_Y' : landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y,\n",
    "                                                'RIGHT_KNEE_X' : landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,\n",
    "                                                'RIGHT_KNEE_Y' : landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y,\n",
    "                                                'LEFT_ANKLE_X' : landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n",
    "                                                'LEFT_ANKLE_Y' : landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y,\n",
    "                                                'RIGHT_ANKLE_X' : landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,\n",
    "                                                'RIGHT_ANKLE_Y' : landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y,\n",
    "                                                'LEFT_HEEL_X' : landmarks[mp_pose.PoseLandmark.LEFT_HEEL.value].x,\n",
    "                                                'LEFT_HEEL_Y' : landmarks[mp_pose.PoseLandmark.LEFT_HEEL.value].y,\n",
    "                                                'RIGHT_HEEL_X' : landmarks[mp_pose.PoseLandmark.RIGHT_HEEL.value].x, \n",
    "                                                'RIGHT_HEEL_Y' : landmarks[mp_pose.PoseLandmark.RIGHT_HEEL.value].y,\n",
    "                                                'LEFT_FOOT_INDEX_X' : landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value].x,  \n",
    "                                                'LEFT_FOOT_INDEX_Y' : landmarks[mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value].y,  \n",
    "                                                'RIGHT_FOOT_INDEX_X' : landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value].x,\n",
    "                                                'RIGHT_FOOT_INDEX_Y' : landmarks[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value].y,\n",
    "                                                'PATH' : key,\n",
    "                                                'EXERCICE' : ex}\n",
    "\n",
    "                                    data_train = data_train.append(new_entry,ignore_index=True)\n",
    "                        except :\n",
    "                            pass\n",
    "\n",
    "    data_train.to_csv(srcpath + '/' + name + '.csv',index=False)\n",
    "    return data_train\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing exercice pullup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 612/612 [00:38<00:00, 15.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing exercice pushup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 683/683 [00:41<00:00, 16.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing exercice situp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 959/959 [01:01<00:00, 15.56it/s]\n"
     ]
    }
   ],
   "source": [
    "df_train = generate_tabular_dataset('./Data Train','train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing exercice pullup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:16<00:00, 18.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing exercice pushup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 303/303 [00:21<00:00, 14.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing exercice situp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 521/521 [00:33<00:00, 15.60it/s]\n"
     ]
    }
   ],
   "source": [
    "df_test = generate_tabular_dataset('./Data Test','test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = ['NOISE_X', 'NOISE_Y', 'LEFT_SHOULDER_X', 'LEFT_SHOULDER_Y',\n",
    "       'RIGHT_SHOULDER_X', 'RIGHT_SHOULDER_Y', 'LEFT_ELBOW_X', 'LEFT_ELBOW_Y',\n",
    "       'RIGHT_ELBOW_X', 'RIGHT_ELBOW_Y', 'LEFT_WRIST_X', 'LEFT_WRIST_Y',\n",
    "       'RIGHT_WRIST_X', 'RIGHT_WRIST_Y', 'LEFT_PINKY_X', 'LEFT_PINKY_Y',\n",
    "       'RIGHT_PINKY_X', 'RIGHT_PINKY_Y', 'LEFT_INDEX_X', 'LEFT_INDEX_Y',\n",
    "       'RIGHT_INDEX_X', 'RIGHT_INDEX_Y', 'LEFT_THUMB_X', 'LEFT_THUMB_Y',\n",
    "       'RIGHT_THUMB_X', 'RIGHT_THUMB_Y', 'LEFT_HIP_X', 'LEFT_HIP_Y',\n",
    "       'RIGHT_HIP_X', 'RIGHT_HIP_Y', 'LEFT_KNEE_X', 'LEFT_KNEE_Y',\n",
    "       'RIGHT_KNEE_X', 'RIGHT_KNEE_Y', 'LEFT_ANKLE_X', 'LEFT_ANKLE_Y',\n",
    "       'RIGHT_ANKLE_X', 'RIGHT_ANKLE_Y', 'LEFT_HEEL_X', 'LEFT_HEEL_Y',\n",
    "       'RIGHT_HEEL_X', 'RIGHT_HEEL_Y', 'LEFT_FOOT_INDEX_X',\n",
    "       'LEFT_FOOT_INDEX_Y', 'RIGHT_FOOT_INDEX_X', 'RIGHT_FOOT_INDEX_Y']\n",
    "       \n",
    "target = 'EXERCICE'\n",
    "encode = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[X_cols].apply(lambda x : x - np.mean(x),axis=1)\n",
    "y_train = encode.fit_transform(df_train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test[X_cols].apply(lambda x : x - np.mean(x),axis=1)\n",
    "y_test = encode.transform(df_test[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(64,activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(32,activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(3,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'SparseCategoricalCrossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "97/97 [==============================] - 1s 4ms/step - loss: 0.8866 - val_loss: 0.6794\n",
      "Epoch 2/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.6321 - val_loss: 0.5262\n",
      "Epoch 3/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.5438 - val_loss: 0.4620\n",
      "Epoch 4/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4778 - val_loss: 0.4109\n",
      "Epoch 5/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4542 - val_loss: 0.3956\n",
      "Epoch 6/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4329 - val_loss: 0.3583\n",
      "Epoch 7/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4267 - val_loss: 0.3468\n",
      "Epoch 8/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3969 - val_loss: 0.3330\n",
      "Epoch 9/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4003 - val_loss: 0.3326\n",
      "Epoch 10/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3952 - val_loss: 0.3257\n",
      "Epoch 11/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3841 - val_loss: 0.3279\n",
      "Epoch 12/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3678 - val_loss: 0.3223\n",
      "Epoch 13/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3645 - val_loss: 0.3217\n",
      "Epoch 14/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3478 - val_loss: 0.3110\n",
      "Epoch 15/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3538 - val_loss: 0.3047\n",
      "Epoch 16/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3465 - val_loss: 0.2954\n",
      "Epoch 17/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3515 - val_loss: 0.2979\n",
      "Epoch 18/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3473 - val_loss: 0.3100\n",
      "Epoch 19/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3473 - val_loss: 0.3005\n",
      "Epoch 20/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3340 - val_loss: 0.3069\n",
      "Epoch 21/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3377 - val_loss: 0.3049\n",
      "Epoch 22/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3397 - val_loss: 0.2948\n",
      "Epoch 23/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3348 - val_loss: 0.2831\n",
      "Epoch 24/200\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.325 - 0s 2ms/step - loss: 0.3250 - val_loss: 0.2932\n",
      "Epoch 25/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3239 - val_loss: 0.2986\n",
      "Epoch 26/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3356 - val_loss: 0.2887\n",
      "Epoch 27/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3209 - val_loss: 0.2893\n",
      "Epoch 28/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3239 - val_loss: 0.2881\n",
      "Epoch 29/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3271 - val_loss: 0.2862\n",
      "Epoch 30/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3268 - val_loss: 0.2995\n",
      "Epoch 31/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3081 - val_loss: 0.2907\n",
      "Epoch 32/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3089 - val_loss: 0.2865\n",
      "Epoch 33/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3168 - val_loss: 0.3095\n",
      "Epoch 34/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3046 - val_loss: 0.2951\n",
      "Epoch 35/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3062 - val_loss: 0.2931\n",
      "Epoch 36/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3022 - val_loss: 0.3014\n",
      "Epoch 37/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3046 - val_loss: 0.2904\n",
      "Epoch 38/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3087 - val_loss: 0.2963\n",
      "Epoch 39/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3073 - val_loss: 0.2889\n",
      "Epoch 40/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2969 - val_loss: 0.3030\n",
      "Epoch 41/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3001 - val_loss: 0.2912\n",
      "Epoch 42/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2970 - val_loss: 0.3011\n",
      "Epoch 43/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2987 - val_loss: 0.2930\n",
      "Epoch 44/200\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.305 - 0s 2ms/step - loss: 0.3097 - val_loss: 0.2939\n",
      "Epoch 45/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2952 - val_loss: 0.2860\n",
      "Epoch 46/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3116 - val_loss: 0.2786\n",
      "Epoch 47/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2964 - val_loss: 0.2839\n",
      "Epoch 48/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2984 - val_loss: 0.2925\n",
      "Epoch 49/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2867 - val_loss: 0.2918\n",
      "Epoch 50/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3043 - val_loss: 0.2759\n",
      "Epoch 51/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2803 - val_loss: 0.2733\n",
      "Epoch 52/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3157 - val_loss: 0.2698\n",
      "Epoch 53/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2836 - val_loss: 0.2819\n",
      "Epoch 54/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2924 - val_loss: 0.2944\n",
      "Epoch 55/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2918 - val_loss: 0.2706\n",
      "Epoch 56/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2837 - val_loss: 0.2754\n",
      "Epoch 57/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2755 - val_loss: 0.2928\n",
      "Epoch 58/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2844 - val_loss: 0.2841\n",
      "Epoch 59/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2745 - val_loss: 0.2676\n",
      "Epoch 60/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2784 - val_loss: 0.2876\n",
      "Epoch 61/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2865 - val_loss: 0.2914\n",
      "Epoch 62/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2904 - val_loss: 0.2705\n",
      "Epoch 63/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2797 - val_loss: 0.2656\n",
      "Epoch 64/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2771 - val_loss: 0.2962\n",
      "Epoch 65/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2803 - val_loss: 0.2932\n",
      "Epoch 66/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2713 - val_loss: 0.2965\n",
      "Epoch 67/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2754 - val_loss: 0.2885\n",
      "Epoch 68/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2778 - val_loss: 0.3145\n",
      "Epoch 69/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2721 - val_loss: 0.2971\n",
      "Epoch 70/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2843 - val_loss: 0.2969\n",
      "Epoch 71/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2723 - val_loss: 0.2801\n",
      "Epoch 72/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2796 - val_loss: 0.2705\n",
      "Epoch 73/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2726 - val_loss: 0.2778\n",
      "Epoch 74/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2741 - val_loss: 0.2789\n",
      "Epoch 75/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2705 - val_loss: 0.2724\n",
      "Epoch 76/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2735 - val_loss: 0.2729\n",
      "Epoch 77/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2829 - val_loss: 0.2791\n",
      "Epoch 78/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2705 - val_loss: 0.2736\n",
      "Epoch 79/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2780 - val_loss: 0.2595\n",
      "Epoch 80/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2640 - val_loss: 0.2735\n",
      "Epoch 81/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2691 - val_loss: 0.2677\n",
      "Epoch 82/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2613 - val_loss: 0.2707\n",
      "Epoch 83/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2653 - val_loss: 0.2652\n",
      "Epoch 84/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2837 - val_loss: 0.2626\n",
      "Epoch 85/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2703 - val_loss: 0.2550\n",
      "Epoch 86/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2919 - val_loss: 0.2433\n",
      "Epoch 87/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2599 - val_loss: 0.2560\n",
      "Epoch 88/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2513 - val_loss: 0.2569\n",
      "Epoch 89/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2700 - val_loss: 0.2456\n",
      "Epoch 90/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2583 - val_loss: 0.2614\n",
      "Epoch 91/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2669 - val_loss: 0.2763\n",
      "Epoch 92/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2640 - val_loss: 0.2729\n",
      "Epoch 93/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2578 - val_loss: 0.2736\n",
      "Epoch 94/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2657 - val_loss: 0.2737\n",
      "Epoch 95/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2671 - val_loss: 0.2606\n",
      "Epoch 96/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2785 - val_loss: 0.2372\n",
      "Epoch 97/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2511 - val_loss: 0.2494\n",
      "Epoch 98/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2586 - val_loss: 0.2609\n",
      "Epoch 99/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2602 - val_loss: 0.2520\n",
      "Epoch 100/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2550 - val_loss: 0.2451\n",
      "Epoch 101/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2560 - val_loss: 0.2498\n",
      "Epoch 102/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2585 - val_loss: 0.2500\n",
      "Epoch 103/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2717 - val_loss: 0.2468\n",
      "Epoch 104/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2691 - val_loss: 0.2535\n",
      "Epoch 105/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2602 - val_loss: 0.2634\n",
      "Epoch 106/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2601 - val_loss: 0.2716\n",
      "Epoch 107/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2557 - val_loss: 0.2665\n",
      "Epoch 108/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2664 - val_loss: 0.2496\n",
      "Epoch 109/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2646 - val_loss: 0.2498\n",
      "Epoch 110/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2477 - val_loss: 0.2642\n",
      "Epoch 111/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2593 - val_loss: 0.2669\n",
      "Epoch 112/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2712 - val_loss: 0.2690\n",
      "Epoch 113/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2590 - val_loss: 0.2773\n",
      "Epoch 114/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2692 - val_loss: 0.2667\n",
      "Epoch 115/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2560 - val_loss: 0.2512\n",
      "Epoch 116/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2563 - val_loss: 0.2411\n",
      "Epoch 117/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2530 - val_loss: 0.2520\n",
      "Epoch 118/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2691 - val_loss: 0.2430\n",
      "Epoch 119/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2548 - val_loss: 0.2621\n",
      "Epoch 120/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2531 - val_loss: 0.2593\n",
      "Epoch 121/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2647 - val_loss: 0.2510\n",
      "Epoch 122/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2587 - val_loss: 0.2511\n",
      "Epoch 123/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2616 - val_loss: 0.2533\n",
      "Epoch 124/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2615 - val_loss: 0.2582\n",
      "Epoch 125/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2549 - val_loss: 0.2438\n",
      "Epoch 126/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2450 - val_loss: 0.2566\n",
      "Epoch 127/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2329 - val_loss: 0.2745\n",
      "Epoch 128/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2495 - val_loss: 0.2571\n",
      "Epoch 129/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2621 - val_loss: 0.2508\n",
      "Epoch 130/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2518 - val_loss: 0.2482\n",
      "Epoch 131/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2540 - val_loss: 0.2552\n",
      "Epoch 132/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2474 - val_loss: 0.2501\n",
      "Epoch 133/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2469 - val_loss: 0.2383\n",
      "Epoch 134/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2464 - val_loss: 0.2558\n",
      "Epoch 135/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2442 - val_loss: 0.2741\n",
      "Epoch 136/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2719 - val_loss: 0.2730\n",
      "Epoch 137/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2572 - val_loss: 0.2599\n",
      "Epoch 138/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2519 - val_loss: 0.2611\n",
      "Epoch 139/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2523 - val_loss: 0.2709\n",
      "Epoch 140/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2514 - val_loss: 0.2671\n",
      "Epoch 141/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2432 - val_loss: 0.2602\n",
      "Epoch 142/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2324 - val_loss: 0.2772\n",
      "Epoch 143/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2465 - val_loss: 0.2824\n",
      "Epoch 144/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2353 - val_loss: 0.2637\n",
      "Epoch 145/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2519 - val_loss: 0.2638\n",
      "Epoch 146/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2524 - val_loss: 0.2569\n",
      "Epoch 147/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2454 - val_loss: 0.2597\n",
      "Epoch 148/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.2701\n",
      "Epoch 149/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2526 - val_loss: 0.2571\n",
      "Epoch 150/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2345 - val_loss: 0.2920\n",
      "Epoch 151/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2344 - val_loss: 0.2666\n",
      "Epoch 152/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2415 - val_loss: 0.2588\n",
      "Epoch 153/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2614 - val_loss: 0.2555\n",
      "Epoch 154/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2467 - val_loss: 0.2597\n",
      "Epoch 155/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2476 - val_loss: 0.2755\n",
      "Epoch 156/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2517 - val_loss: 0.2674\n",
      "Epoch 157/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2450 - val_loss: 0.2452\n",
      "Epoch 158/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2513 - val_loss: 0.2400\n",
      "Epoch 159/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2316 - val_loss: 0.2402\n",
      "Epoch 160/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2526 - val_loss: 0.2566\n",
      "Epoch 161/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2478 - val_loss: 0.2558\n",
      "Epoch 162/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2481 - val_loss: 0.2432\n",
      "Epoch 163/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2378 - val_loss: 0.2507\n",
      "Epoch 164/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2402 - val_loss: 0.2712\n",
      "Epoch 165/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2346 - val_loss: 0.2792\n",
      "Epoch 166/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2398 - val_loss: 0.2846\n",
      "Epoch 167/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2578 - val_loss: 0.2767\n",
      "Epoch 168/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2281 - val_loss: 0.2741\n",
      "Epoch 169/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2333 - val_loss: 0.2586\n",
      "Epoch 170/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.2673\n",
      "Epoch 171/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2454 - val_loss: 0.2522\n",
      "Epoch 172/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2411 - val_loss: 0.2545\n",
      "Epoch 173/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2307 - val_loss: 0.2779\n",
      "Epoch 174/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2345 - val_loss: 0.2633\n",
      "Epoch 175/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2496 - val_loss: 0.2525\n",
      "Epoch 176/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2324 - val_loss: 0.2448\n",
      "Epoch 177/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2442 - val_loss: 0.2565\n",
      "Epoch 178/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2347 - val_loss: 0.2716\n",
      "Epoch 179/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2381 - val_loss: 0.2461\n",
      "Epoch 180/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2396 - val_loss: 0.2624\n",
      "Epoch 181/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2369 - val_loss: 0.2476\n",
      "Epoch 182/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2601 - val_loss: 0.2428\n",
      "Epoch 183/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2477 - val_loss: 0.2518\n",
      "Epoch 184/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2464 - val_loss: 0.2627\n",
      "Epoch 185/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2325 - val_loss: 0.2419\n",
      "Epoch 186/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2699 - val_loss: 0.2564\n",
      "Epoch 187/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2511 - val_loss: 0.2521\n",
      "Epoch 188/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2340 - val_loss: 0.2356\n",
      "Epoch 189/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2381 - val_loss: 0.2403\n",
      "Epoch 190/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2352 - val_loss: 0.2639\n",
      "Epoch 191/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2531 - val_loss: 0.2508\n",
      "Epoch 192/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2420 - val_loss: 0.2582\n",
      "Epoch 193/200\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.242 - 0s 2ms/step - loss: 0.2383 - val_loss: 0.2671\n",
      "Epoch 194/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2303 - val_loss: 0.2883\n",
      "Epoch 195/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2426 - val_loss: 0.2518\n",
      "Epoch 196/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2386 - val_loss: 0.2432\n",
      "Epoch 197/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2503 - val_loss: 0.2596\n",
      "Epoch 198/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2451 - val_loss: 0.2779\n",
      "Epoch 199/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2354 - val_loss: 0.2445\n",
      "Epoch 200/200\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2203 - val_loss: 0.2516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25d32186730>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs = 200,validation_data= (X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_model = model.predict(X_test)\n",
    "predictions = np.argmax(proba_model,axis=1)\n",
    "metrics = tf.keras.metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9405617117881775\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy : {}'.format(metrics(y_test,predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Model/encoder.pkl','wb') as file:\n",
    "    pickle.dump(encode,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Model/model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./Model/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NOISE_X</th>\n",
       "      <th>NOISE_Y</th>\n",
       "      <th>LEFT_SHOULDER_X</th>\n",
       "      <th>LEFT_SHOULDER_Y</th>\n",
       "      <th>RIGHT_SHOULDER_X</th>\n",
       "      <th>RIGHT_SHOULDER_Y</th>\n",
       "      <th>LEFT_ELBOW_X</th>\n",
       "      <th>LEFT_ELBOW_Y</th>\n",
       "      <th>RIGHT_ELBOW_X</th>\n",
       "      <th>RIGHT_ELBOW_Y</th>\n",
       "      <th>...</th>\n",
       "      <th>RIGHT_ANKLE_X</th>\n",
       "      <th>RIGHT_ANKLE_Y</th>\n",
       "      <th>LEFT_HEEL_X</th>\n",
       "      <th>LEFT_HEEL_Y</th>\n",
       "      <th>RIGHT_HEEL_X</th>\n",
       "      <th>RIGHT_HEEL_Y</th>\n",
       "      <th>LEFT_FOOT_INDEX_X</th>\n",
       "      <th>LEFT_FOOT_INDEX_Y</th>\n",
       "      <th>RIGHT_FOOT_INDEX_X</th>\n",
       "      <th>RIGHT_FOOT_INDEX_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059655</td>\n",
       "      <td>0.146964</td>\n",
       "      <td>0.019389</td>\n",
       "      <td>0.085886</td>\n",
       "      <td>0.110014</td>\n",
       "      <td>0.084151</td>\n",
       "      <td>0.010225</td>\n",
       "      <td>0.211571</td>\n",
       "      <td>0.137565</td>\n",
       "      <td>0.210791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180234</td>\n",
       "      <td>-0.542457</td>\n",
       "      <td>-0.052459</td>\n",
       "      <td>-0.572690</td>\n",
       "      <td>0.173818</td>\n",
       "      <td>-0.558042</td>\n",
       "      <td>-0.085460</td>\n",
       "      <td>-0.583785</td>\n",
       "      <td>0.175312</td>\n",
       "      <td>-0.580455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.126713</td>\n",
       "      <td>0.154800</td>\n",
       "      <td>0.071201</td>\n",
       "      <td>0.067161</td>\n",
       "      <td>0.176918</td>\n",
       "      <td>0.061373</td>\n",
       "      <td>0.043105</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.188866</td>\n",
       "      <td>0.013856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213507</td>\n",
       "      <td>-0.437524</td>\n",
       "      <td>0.005811</td>\n",
       "      <td>-0.423736</td>\n",
       "      <td>0.197957</td>\n",
       "      <td>-0.460288</td>\n",
       "      <td>-0.032571</td>\n",
       "      <td>-0.457869</td>\n",
       "      <td>0.260592</td>\n",
       "      <td>-0.526465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013851</td>\n",
       "      <td>-0.126850</td>\n",
       "      <td>0.048552</td>\n",
       "      <td>-0.068604</td>\n",
       "      <td>-0.022612</td>\n",
       "      <td>-0.062302</td>\n",
       "      <td>0.064936</td>\n",
       "      <td>-0.151960</td>\n",
       "      <td>-0.035816</td>\n",
       "      <td>-0.146516</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034327</td>\n",
       "      <td>0.269280</td>\n",
       "      <td>0.026405</td>\n",
       "      <td>0.297228</td>\n",
       "      <td>-0.023487</td>\n",
       "      <td>0.267396</td>\n",
       "      <td>0.019411</td>\n",
       "      <td>0.324483</td>\n",
       "      <td>-0.036927</td>\n",
       "      <td>0.313910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.025829</td>\n",
       "      <td>-0.168910</td>\n",
       "      <td>0.042444</td>\n",
       "      <td>-0.109269</td>\n",
       "      <td>0.019472</td>\n",
       "      <td>-0.103960</td>\n",
       "      <td>0.031089</td>\n",
       "      <td>-0.159862</td>\n",
       "      <td>0.001456</td>\n",
       "      <td>-0.165782</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007913</td>\n",
       "      <td>0.253104</td>\n",
       "      <td>-0.003496</td>\n",
       "      <td>0.248033</td>\n",
       "      <td>-0.007121</td>\n",
       "      <td>0.254263</td>\n",
       "      <td>-0.015090</td>\n",
       "      <td>0.267554</td>\n",
       "      <td>-0.017327</td>\n",
       "      <td>0.279987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.025182</td>\n",
       "      <td>-0.220927</td>\n",
       "      <td>-0.026732</td>\n",
       "      <td>-0.135479</td>\n",
       "      <td>-0.016627</td>\n",
       "      <td>-0.132162</td>\n",
       "      <td>-0.024361</td>\n",
       "      <td>-0.179491</td>\n",
       "      <td>-0.013022</td>\n",
       "      <td>-0.185621</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039470</td>\n",
       "      <td>0.423227</td>\n",
       "      <td>-0.020570</td>\n",
       "      <td>0.456239</td>\n",
       "      <td>-0.032976</td>\n",
       "      <td>0.447588</td>\n",
       "      <td>-0.048008</td>\n",
       "      <td>0.467762</td>\n",
       "      <td>-0.070141</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3087</th>\n",
       "      <td>-0.014262</td>\n",
       "      <td>-0.031979</td>\n",
       "      <td>-0.158272</td>\n",
       "      <td>0.189914</td>\n",
       "      <td>0.122904</td>\n",
       "      <td>0.218721</td>\n",
       "      <td>-0.307927</td>\n",
       "      <td>0.255882</td>\n",
       "      <td>0.217329</td>\n",
       "      <td>0.237005</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008301</td>\n",
       "      <td>-0.252513</td>\n",
       "      <td>-0.075364</td>\n",
       "      <td>-0.268421</td>\n",
       "      <td>-0.024349</td>\n",
       "      <td>-0.220754</td>\n",
       "      <td>-0.073054</td>\n",
       "      <td>-0.383514</td>\n",
       "      <td>-0.048712</td>\n",
       "      <td>-0.323854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3088</th>\n",
       "      <td>-0.047457</td>\n",
       "      <td>-0.021628</td>\n",
       "      <td>-0.188214</td>\n",
       "      <td>0.171701</td>\n",
       "      <td>0.091823</td>\n",
       "      <td>0.214419</td>\n",
       "      <td>-0.311179</td>\n",
       "      <td>0.230552</td>\n",
       "      <td>0.203747</td>\n",
       "      <td>0.221326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035424</td>\n",
       "      <td>-0.281315</td>\n",
       "      <td>-0.053050</td>\n",
       "      <td>-0.179948</td>\n",
       "      <td>-0.002493</td>\n",
       "      <td>-0.236104</td>\n",
       "      <td>-0.011399</td>\n",
       "      <td>-0.256288</td>\n",
       "      <td>-0.043434</td>\n",
       "      <td>-0.317515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089</th>\n",
       "      <td>-0.024854</td>\n",
       "      <td>0.009457</td>\n",
       "      <td>-0.173477</td>\n",
       "      <td>0.210591</td>\n",
       "      <td>0.106834</td>\n",
       "      <td>0.240004</td>\n",
       "      <td>-0.306835</td>\n",
       "      <td>0.229868</td>\n",
       "      <td>0.205535</td>\n",
       "      <td>0.226209</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021732</td>\n",
       "      <td>-0.194997</td>\n",
       "      <td>-0.092743</td>\n",
       "      <td>-0.175948</td>\n",
       "      <td>-0.039884</td>\n",
       "      <td>-0.160208</td>\n",
       "      <td>-0.077433</td>\n",
       "      <td>-0.242922</td>\n",
       "      <td>-0.076929</td>\n",
       "      <td>-0.213864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3090</th>\n",
       "      <td>-0.058747</td>\n",
       "      <td>0.023991</td>\n",
       "      <td>-0.182079</td>\n",
       "      <td>0.184939</td>\n",
       "      <td>0.087930</td>\n",
       "      <td>0.232544</td>\n",
       "      <td>-0.279061</td>\n",
       "      <td>0.203701</td>\n",
       "      <td>0.201429</td>\n",
       "      <td>0.199585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019222</td>\n",
       "      <td>-0.236978</td>\n",
       "      <td>-0.053823</td>\n",
       "      <td>-0.158335</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>-0.205713</td>\n",
       "      <td>-0.002739</td>\n",
       "      <td>-0.220655</td>\n",
       "      <td>-0.023191</td>\n",
       "      <td>-0.270021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3091</th>\n",
       "      <td>-0.014880</td>\n",
       "      <td>0.051292</td>\n",
       "      <td>-0.158451</td>\n",
       "      <td>0.219712</td>\n",
       "      <td>0.121005</td>\n",
       "      <td>0.263429</td>\n",
       "      <td>-0.289303</td>\n",
       "      <td>0.215394</td>\n",
       "      <td>0.228735</td>\n",
       "      <td>0.268518</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034908</td>\n",
       "      <td>-0.218961</td>\n",
       "      <td>-0.106362</td>\n",
       "      <td>-0.149004</td>\n",
       "      <td>-0.046614</td>\n",
       "      <td>-0.189623</td>\n",
       "      <td>-0.095931</td>\n",
       "      <td>-0.236818</td>\n",
       "      <td>-0.082547</td>\n",
       "      <td>-0.252683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3092 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       NOISE_X   NOISE_Y  LEFT_SHOULDER_X  LEFT_SHOULDER_Y  RIGHT_SHOULDER_X  \\\n",
       "0     0.059655  0.146964         0.019389         0.085886          0.110014   \n",
       "1     0.126713  0.154800         0.071201         0.067161          0.176918   \n",
       "2     0.013851 -0.126850         0.048552        -0.068604         -0.022612   \n",
       "3     0.025829 -0.168910         0.042444        -0.109269          0.019472   \n",
       "4    -0.025182 -0.220927        -0.026732        -0.135479         -0.016627   \n",
       "...        ...       ...              ...              ...               ...   \n",
       "3087 -0.014262 -0.031979        -0.158272         0.189914          0.122904   \n",
       "3088 -0.047457 -0.021628        -0.188214         0.171701          0.091823   \n",
       "3089 -0.024854  0.009457        -0.173477         0.210591          0.106834   \n",
       "3090 -0.058747  0.023991        -0.182079         0.184939          0.087930   \n",
       "3091 -0.014880  0.051292        -0.158451         0.219712          0.121005   \n",
       "\n",
       "      RIGHT_SHOULDER_Y  LEFT_ELBOW_X  LEFT_ELBOW_Y  RIGHT_ELBOW_X  \\\n",
       "0             0.084151      0.010225      0.211571       0.137565   \n",
       "1             0.061373      0.043105      0.006470       0.188866   \n",
       "2            -0.062302      0.064936     -0.151960      -0.035816   \n",
       "3            -0.103960      0.031089     -0.159862       0.001456   \n",
       "4            -0.132162     -0.024361     -0.179491      -0.013022   \n",
       "...                ...           ...           ...            ...   \n",
       "3087          0.218721     -0.307927      0.255882       0.217329   \n",
       "3088          0.214419     -0.311179      0.230552       0.203747   \n",
       "3089          0.240004     -0.306835      0.229868       0.205535   \n",
       "3090          0.232544     -0.279061      0.203701       0.201429   \n",
       "3091          0.263429     -0.289303      0.215394       0.228735   \n",
       "\n",
       "      RIGHT_ELBOW_Y  ...  RIGHT_ANKLE_X  RIGHT_ANKLE_Y  LEFT_HEEL_X  \\\n",
       "0          0.210791  ...       0.180234      -0.542457    -0.052459   \n",
       "1          0.013856  ...       0.213507      -0.437524     0.005811   \n",
       "2         -0.146516  ...      -0.034327       0.269280     0.026405   \n",
       "3         -0.165782  ...      -0.007913       0.253104    -0.003496   \n",
       "4         -0.185621  ...      -0.039470       0.423227    -0.020570   \n",
       "...             ...  ...            ...            ...          ...   \n",
       "3087       0.237005  ...      -0.008301      -0.252513    -0.075364   \n",
       "3088       0.221326  ...       0.035424      -0.281315    -0.053050   \n",
       "3089       0.226209  ...      -0.021732      -0.194997    -0.092743   \n",
       "3090       0.199585  ...       0.019222      -0.236978    -0.053823   \n",
       "3091       0.268518  ...      -0.034908      -0.218961    -0.106362   \n",
       "\n",
       "      LEFT_HEEL_Y  RIGHT_HEEL_X  RIGHT_HEEL_Y  LEFT_FOOT_INDEX_X  \\\n",
       "0       -0.572690      0.173818     -0.558042          -0.085460   \n",
       "1       -0.423736      0.197957     -0.460288          -0.032571   \n",
       "2        0.297228     -0.023487      0.267396           0.019411   \n",
       "3        0.248033     -0.007121      0.254263          -0.015090   \n",
       "4        0.456239     -0.032976      0.447588          -0.048008   \n",
       "...           ...           ...           ...                ...   \n",
       "3087    -0.268421     -0.024349     -0.220754          -0.073054   \n",
       "3088    -0.179948     -0.002493     -0.236104          -0.011399   \n",
       "3089    -0.175948     -0.039884     -0.160208          -0.077433   \n",
       "3090    -0.158335      0.002688     -0.205713          -0.002739   \n",
       "3091    -0.149004     -0.046614     -0.189623          -0.095931   \n",
       "\n",
       "      LEFT_FOOT_INDEX_Y  RIGHT_FOOT_INDEX_X  RIGHT_FOOT_INDEX_Y  \n",
       "0             -0.583785            0.175312           -0.580455  \n",
       "1             -0.457869            0.260592           -0.526465  \n",
       "2              0.324483           -0.036927            0.313910  \n",
       "3              0.267554           -0.017327            0.279987  \n",
       "4              0.467762           -0.070141            0.460726  \n",
       "...                 ...                 ...                 ...  \n",
       "3087          -0.383514           -0.048712           -0.323854  \n",
       "3088          -0.256288           -0.043434           -0.317515  \n",
       "3089          -0.242922           -0.076929           -0.213864  \n",
       "3090          -0.220655           -0.023191           -0.270021  \n",
       "3091          -0.236818           -0.082547           -0.252683  \n",
       "\n",
       "[3092 rows x 46 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8714aa734682364d8708944b8e407a97176dc16799c667e4a9047caae3833205"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('dlcourse': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
